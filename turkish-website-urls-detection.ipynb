{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe437888",
   "metadata": {},
   "source": [
    "# Collecting Turkish website URLs\n",
    "We have WARC files and news websites list from Basin Ilan Kurumu.\\\n",
    "First we will try to find websites that have Turkish Content from WARC files. \\\n",
    "Then we will merge this data with BIK's list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1652524",
   "metadata": {},
   "source": [
    "### Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa2d4531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: warcio in /opt/anaconda3/lib/python3.12/site-packages (1.7.5)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (4.66.5)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.12/site-packages (from warcio) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install warcio tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf584b0",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0c0c07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARC dosyaları: ['./data/CC-NEWS-20250103095544-00180.warc', './data/CC-NEWS-20250102092617-00168.warc', './data/CC-NEWS-20250101055537-00157.warc', './data/CC-NEWS-20250101233509-00164.warc', './data/CC-NEWS-20250102214004-00175.warc', './data/CC-NEWS-20250103181014-00185.warc', './data/CC-NEWS-20250103145501-00183.warc', './data/CC-NEWS-20250101110352-00159.warc', './data/CC-NEWS-20250102074538-00167.warc', './data/CC-NEWS-20250102110149-00169.warc', './data/CC-NEWS-20200110212037-00310.warc', './data/CC-NEWS-20250102140759-00171.warc', './data/CC-NEWS-20250102053830-00166.warc', './data/CC-NEWS-20250103060152-00178.warc', './data/CC-NEWS-20250101182853-00162.warc', './data/CC-NEWS-20250102155145-00172.warc', './data/CC-NEWS-20250101204758-00163.warc', './data/CC-NEWS-20250103080404-00179.warc', './data/CC-NEWS-20250102192440-00174.warc', './data/CC-NEWS-20250102122438-00170.warc', './data/CC-NEWS-20250102173620-00173.warc', './data/CC-NEWS-20250103114344-00181.warc', './data/CC-NEWS-20250101083312-00158.warc', './data/CC-NEWS-20250101160900-00161.warc', './data/CC-NEWS-20250103031223-00177.warc', './data/CC-NEWS-20250103000559-00176.warc', './data/CC-NEWS-20250101133323-00160.warc', './data/CC-NEWS-20250103131849-00182.warc', './data/CC-NEWS-20250103163233-00184.warc', './data/CC-NEWS-20250101020153-00156.warc', './data/CC-NEWS-20250102025043-00165.warc']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_folder = './data'\n",
    "warc_files = [os.path.join(data_folder, f) for f in os.listdir(data_folder) if f.endswith('.warc')]\n",
    "print(\"WARC dosyaları:\", warc_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8833f6cc",
   "metadata": {},
   "source": [
    "### Collect URLs that have Turkish content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32350488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing WARC files:  90%|█████████ | 28/31 [10:29<01:09, 23.22s/it]"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "from warcio.archiveiterator import ArchiveIterator\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def is_turkish_text(content, min_unique=3, debug=False):\n",
    "    \"\"\"\n",
    "    İçerikteki Türkçe karakterler arasında, farklı (unique) karakter sayısı min_unique'ten fazla ise\n",
    "    içerik Türkçe kabul edilir.\n",
    "    \"\"\"\n",
    "    # Türkçe karakterler: ç, ğ, ı, ö, ş, ü (büyük ve küçük)\n",
    "    turkish_chars = \"çğıöşüÇĞİÖŞÜ\"\n",
    "    matches = re.findall(f\"[{turkish_chars}]\", content)\n",
    "    unique_chars = set(matches)\n",
    "    if debug:\n",
    "        print(f\"Bulunan karakterler: {matches}\")\n",
    "        print(f\"Unique karakterler: {unique_chars}\")\n",
    "    return len(unique_chars) > min_unique\n",
    "\n",
    "def list_turkish_urls_by_chars(warc_file, read_bytes=20000, debug=False):\n",
    "    \"\"\"Bir WARC dosyasındaki, içerikte Türkçe karakterlerin varlığına bakarak Türkçe URL'leri döndürür.\"\"\"\n",
    "    turkish_urls = []\n",
    "    try:\n",
    "        with open(warc_file, 'rb') as f:\n",
    "            for record in ArchiveIterator(f):\n",
    "                if record.rec_type == 'response':\n",
    "                    try:\n",
    "                        content = record.content_stream().read(read_bytes).decode('utf-8', errors='ignore')\n",
    "                        if content.strip() and is_turkish_text(content, debug=debug):\n",
    "                            url = record.rec_headers.get_header('WARC-Target-URI')\n",
    "                            if url:\n",
    "                                turkish_urls.append(url)\n",
    "                    except Exception as error:\n",
    "                        if debug:\n",
    "                            print(\"Record işlenirken hata:\", error)\n",
    "                        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {warc_file}: {e}\")\n",
    "    return turkish_urls\n",
    "\n",
    "# WARC dosyalarını işleyip Türkçe URL'leri toplayalım\n",
    "all_turkish_urls = []\n",
    "all_turkish_urls_counts = {}\n",
    "\n",
    "for warc_file in tqdm(warc_files, desc=\"Processing WARC files\"):\n",
    "    urls = list_turkish_urls_by_chars(warc_file, debug=False)\n",
    "    all_turkish_urls_counts[warc_file] = len(urls)\n",
    "    all_turkish_urls.extend(urls)\n",
    "\n",
    "print(f\"\\nToplamda {len(all_turkish_urls)} adet Türkçe URL bulundu.\")\n",
    "print(\"\\nWARC dosyalarındaki Türkçe URL sayıları:\\n\", all_turkish_urls_counts)\n",
    "\n",
    "# all_turkish_urls listesinde bulunan tüm URL'lerden unique domain'leri alalım\n",
    "unique_domains = {urlparse(url).netloc for url in all_turkish_urls if url}\n",
    "\n",
    "print(\"Unique domains:\", unique_domains)\n",
    "for domain in unique_domains:\n",
    "    print(domain)\n",
    "\n",
    "# unique_domains değişkeninin oluşturulmuş olduğunu varsayıyoruz.\n",
    "with open('./websites/warc-turkish-url-list.txt', 'w', encoding='utf-8') as f:\n",
    "    for domain in sorted(unique_domains):\n",
    "        f.write(domain + \"\\n\")\n",
    "\n",
    "print(f\"Exported {len(unique_domains)} domains to warc-turkish-url-list.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb853a51",
   "metadata": {},
   "source": [
    "### Merge WARC URLs with BIK URLs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
